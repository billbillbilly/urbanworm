{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Urban-Worm","text":"<p>A python package for studying urban environment imagery with Llama vison model</p>"},{"location":"#introduction","title":"Introduction","text":"<p>Urban-Worm is a Python library that integrates remote sensing imagery, street view data, and multimodal model to assess urban units. Using APIs for data collection and Llama 3.2 vision for inference, Urban-Worm is designed to support the automation of the evaluation for urban environments, including roof integrity, structural condition, landscape quality, and urban perception.</p> <p> </p>"},{"location":"#features","title":"Features","text":"<ul> <li>run Llama 3.2 vision locally with local datasets and remain information privacy</li> <li>download building footprints from OSM and global building released by Bing map </li> <li>search and clip aerial and street view images (via APIs) based on urban units such as parcel and building footprint data</li> <li>automatically calibrate the oritation of panorama street view and the extent of aerial image</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>The package is heavily built on Ollama client, Ollama-python, and Llama 3.2 Vision. Credit goes to the developers of these projects.</p> <ul> <li>ollama</li> <li>ollama-python</li> <li>structured outputs</li> <li>llama 3.2 vision</li> </ul> <p>The functionality about sourcing and processing GIS data (satellite &amp; street view imagery) is built on the following open projects. Credit goes to the developers of these projects.</p> <ul> <li>tms2geotiff</li> <li>GlobalMLBuildingFootprints</li> <li>Mapillary API</li> </ul> <p>The development of this package is supported and inspired by the city of Detroit.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#step-1-install-ollama-client","title":"Step 1: install Ollama client","text":"<p>Please make sure Ollama is installed before installing urban-worm</p>"},{"location":"installation/#linux","title":"Linux","text":"<p>For Linux, users can also install ollama by running in the terminal:</p> <pre><code>curl -fsSL https://ollama.com/install.sh | sh\n</code></pre>"},{"location":"installation/#mac","title":"MAC","text":"<p>For MacOS, users can also install ollama using <code>brew</code>:</p> <pre><code>brew install ollama\n</code></pre> <p>To install <code>brew</code>, run in the terminal:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> <p>After installing <code>brew</code>, you will see a following instruction:</p> <pre><code>==&gt; Next steps:\n- Run these commands in your terminal to add Homebrew to your PATH:\n    echo &gt;&gt; /Users/yourusername/.bash_profile\n    echo 'eval \"$(/opt/homebrew/bin/brew shellenv)\"' &gt;&gt; /Users/yourusername/.bash_profile\n    eval \"$(/opt/homebrew/bin/brew shellenv)\"\n</code></pre>"},{"location":"installation/#windows","title":"Windows","text":"<p>Windows users should directly install the Ollama client</p>"},{"location":"installation/#step-2-install-gdal-first","title":"Step 2: install GDAL first","text":"<p>For macOS, Linux, and Windows users, <code>gdal</code> may need to be installed at very begining using <code>conda</code>. </p>"},{"location":"installation/#install-conda","title":"install conda","text":"<p>Please download and install Anaconda to use <code>conda</code>.</p>"},{"location":"installation/#install-gdal","title":"install GDAL","text":"<p>If the installation method above does not work, try to install with <code>conda</code>:</p> <pre><code> conda install -c conda-forge gdal\n</code></pre> <p>Mac users may install <code>gdal</code> (if the installation method below does not work, try to install with conda):</p> <pre><code> brew install gdal\n</code></pre>"},{"location":"installation/#note","title":"Note","text":"<p>if you come across error like <code>conda command not found</code> when using <code>conda</code>, please refer following solutions to add Conda to the PATH:</p> <ul> <li>Linux: <code>export PATH=~/anaconda3/bin:$PATH</code> (source)</li> <li>Mac: <code>export PATH=\"/home/username/miniconda/bin:$PATH\"</code>. Please make sure to replace <code>/home/username/miniconda</code> with your actual path (source)</li> <li>Windows: Open Anaconda Prompt &gt; Check Conda Installed Location: <code>where conda</code> &gt; Open Advanced System Settings &gt; Click on Environment Variables &gt; Edit Path &gt; Add New Path: </li> </ul> <pre><code> C:\\Users\\&lt;username&gt;\\Anaconda3\\Scripts\n C:\\Users\\&lt;username&gt;\\Anaconda3\n C:\\Users\\&lt;username&gt;\\Anaconda3\\Library\\bin\n</code></pre> <p>(source)</p>"},{"location":"installation/#step-3-install-urabn-worm-from-pypi","title":"Step 3: install urabn-worm from PyPi","text":"<p>The package urabnworm can be installed with <code>pip</code>:</p> <pre><code>pip install urban-worm \n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use urban-worm in a project:</p> <pre><code>from urbanworm import UrbanDataSet\n</code></pre>"},{"location":"usage/#single-image","title":"single-image","text":"<pre><code># load a local image\ndata = UrbanDataSet(image = './docs/data/test1.jpg')\nsystem = '''\n    Given a top view image, you are going to roughly estimate house conditions. Your answer should be based only on your observation. \n    The format of your response must include question, answer (yes or no), explanation (within 50 words)\n'''\nprompt = '''\n    Is there any damage on the roof?\n'''\ndata.oneImgChat(system=system, prompt=prompt)\n# output:\n# {'question': 'Is there any damage on the roof?',\n#  'answer': 'no',\n#  'explanation': 'No visible signs of damage or wear on the roof',\n#  'img': '/9j/4AAQSkZ...'}\n</code></pre>"},{"location":"usage/#multiple-images-using-osm-data-and-mapillary-api","title":"multiple images using OSM data and Mapillary API","text":"<p>Get building footprints as units and collect satellite and street view images based on each unit. Finally, chat with MLLM model for each unit based on collected images.</p> <p>To get a token/key to access data via mapillary api, please create an acount and apply on Mapillary</p> <pre><code>bbox = (-83.235572,42.348092,-83.235154,42.348806)\ndata = UrbanDataSet()\ndata.bbox2Buildings(bbox, source='osm')\n\nsystem = '''\n    Given a top view image or street view images, you are going to roughly estimate house conditions. \n    Your answer should be based only on your observation. \n    The format of your response must include question, answer (yes or no), explanation (within 50 words) for each question.\n'''\n\nprompt = {\n    'top': '''\n        Is there any damage on the roof?\n    ''',\n    'street': '''\n        Is the wall missing or damaged?\n        Is the yard maintained well?\n    '''\n}\n\n# add the Mapillary key\ndata.mapillary_key = 'MLY|......'\n# use both the aerial and street view images (with type='both')\ndata.loopUnitChat(system=system, prompt=prompt, type='both', epsg=2253)\n# convert results into GeoDataframe\ndata.to_gdf()\n</code></pre>"}]}